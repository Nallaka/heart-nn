{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Import all the necessary dependencies."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set the relevant hyper-parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [],
   "source": [
    "dataset_path = \"data\\processed\\processed.cleveland.csv\"\n",
    "train_test_ratio = 0.9  # Ratio of training examples to test examples\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "learning_rate = 1.0e-4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Ingestion Check"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Shape: (302, 14) \n",
      "\n",
      "X:\n",
      "\n",
      "     63.0  1.0  1.0.1  145.0  233.0  1.0.2  2.0  150.0  0.0  2.3  3.0  0.0.1  \\\n",
      "0    67.0  1.0    4.0  160.0  286.0    0.0  2.0  108.0  1.0  1.5  2.0    3.0   \n",
      "1    67.0  1.0    4.0  120.0  229.0    0.0  2.0  129.0  1.0  2.6  2.0    2.0   \n",
      "2    37.0  1.0    3.0  130.0  250.0    0.0  0.0  187.0  0.0  3.5  3.0    0.0   \n",
      "3    41.0  0.0    2.0  130.0  204.0    0.0  2.0  172.0  0.0  1.4  1.0    0.0   \n",
      "4    56.0  1.0    2.0  120.0  236.0    0.0  0.0  178.0  0.0  0.8  1.0    0.0   \n",
      "..    ...  ...    ...    ...    ...    ...  ...    ...  ...  ...  ...    ...   \n",
      "297  45.0  1.0    1.0  110.0  264.0    0.0  0.0  132.0  0.0  1.2  2.0    0.0   \n",
      "298  68.0  1.0    4.0  144.0  193.0    1.0  0.0  141.0  0.0  3.4  2.0    2.0   \n",
      "299  57.0  1.0    4.0  130.0  131.0    0.0  0.0  115.0  1.0  1.2  2.0    1.0   \n",
      "300  57.0  0.0    2.0  130.0  236.0    0.0  2.0  174.0  0.0  0.0  2.0    1.0   \n",
      "301  38.0  1.0    3.0  138.0  175.0    0.0  0.0  173.0  0.0  0.0  1.0    0.0   \n",
      "\n",
      "     6.0  \n",
      "0    3.0  \n",
      "1    7.0  \n",
      "2    3.0  \n",
      "3    3.0  \n",
      "4    3.0  \n",
      "..   ...  \n",
      "297  7.0  \n",
      "298  7.0  \n",
      "299  7.0  \n",
      "300  3.0  \n",
      "301  3.0  \n",
      "\n",
      "[302 rows x 13 columns]\n",
      "\n",
      "y:\n",
      "\n",
      "0      2\n",
      "1      1\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "297    1\n",
      "298    2\n",
      "299    3\n",
      "300    1\n",
      "301    0\n",
      "Name: 0, Length: 302, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "file = pd.read_csv(dataset_path)\n",
    "\n",
    "X_shape, y_shape = file.shape\n",
    "print(\"File Shape: (\" + str(X_shape) + \", \" + str(y_shape) + \") \\n\")\n",
    "\n",
    "X = file.iloc[0:, :y_shape - 1]\n",
    "y = file.iloc[0:, y_shape - 1]\n",
    "\n",
    "print(\"X:\\n\")\n",
    "print(X)\n",
    "print(\"\\ny:\\n\")\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "__Note:__ The given datasets are contained in one file, so we will split into training and validation examples with the defined ratio."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train\n",
      "     63.0  1.0  1.0.1  145.0  233.0  1.0.2  2.0  150.0  0.0  2.3  3.0  0.0.1  \\\n",
      "0    67.0  1.0    4.0  160.0  286.0    0.0  2.0  108.0  1.0  1.5  2.0    3.0   \n",
      "1    67.0  1.0    4.0  120.0  229.0    0.0  2.0  129.0  1.0  2.6  2.0    2.0   \n",
      "2    37.0  1.0    3.0  130.0  250.0    0.0  0.0  187.0  0.0  3.5  3.0    0.0   \n",
      "3    41.0  0.0    2.0  130.0  204.0    0.0  2.0  172.0  0.0  1.4  1.0    0.0   \n",
      "4    56.0  1.0    2.0  120.0  236.0    0.0  0.0  178.0  0.0  0.8  1.0    0.0   \n",
      "..    ...  ...    ...    ...    ...    ...  ...    ...  ...  ...  ...    ...   \n",
      "266  59.0  1.0    3.0  126.0  218.0    1.0  0.0  134.0  0.0  2.2  2.0    1.0   \n",
      "267  40.0  1.0    4.0  152.0  223.0    0.0  0.0  181.0  0.0  0.0  1.0    0.0   \n",
      "268  42.0  1.0    3.0  130.0  180.0    0.0  0.0  150.0  0.0  0.0  1.0    0.0   \n",
      "269  61.0  1.0    4.0  140.0  207.0    0.0  2.0  138.0  1.0  1.9  1.0    1.0   \n",
      "270  66.0  1.0    4.0  160.0  228.0    0.0  2.0  138.0  0.0  2.3  1.0    0.0   \n",
      "\n",
      "     6.0  \n",
      "0    3.0  \n",
      "1    7.0  \n",
      "2    3.0  \n",
      "3    3.0  \n",
      "4    3.0  \n",
      "..   ...  \n",
      "266  6.0  \n",
      "267  7.0  \n",
      "268  3.0  \n",
      "269  7.0  \n",
      "270  6.0  \n",
      "\n",
      "[271 rows x 13 columns]\n",
      "\n",
      "X_test\n",
      "     63.0  1.0  1.0.1  145.0  233.0  1.0.2  2.0  150.0  0.0  2.3  3.0  0.0.1  \\\n",
      "271  46.0  1.0    4.0  140.0  311.0    0.0  0.0  120.0  1.0  1.8  2.0    2.0   \n",
      "272  71.0  0.0    4.0  112.0  149.0    0.0  0.0  125.0  0.0  1.6  2.0    0.0   \n",
      "273  59.0  1.0    1.0  134.0  204.0    0.0  0.0  162.0  0.0  0.8  1.0    2.0   \n",
      "274  64.0  1.0    1.0  170.0  227.0    0.0  2.0  155.0  0.0  0.6  2.0    0.0   \n",
      "275  66.0  0.0    3.0  146.0  278.0    0.0  2.0  152.0  0.0  0.0  2.0    1.0   \n",
      "276  39.0  0.0    3.0  138.0  220.0    0.0  0.0  152.0  0.0  0.0  2.0    0.0   \n",
      "277  57.0  1.0    2.0  154.0  232.0    0.0  2.0  164.0  0.0  0.0  1.0    1.0   \n",
      "278  58.0  0.0    4.0  130.0  197.0    0.0  0.0  131.0  0.0  0.6  2.0    0.0   \n",
      "279  57.0  1.0    4.0  110.0  335.0    0.0  0.0  143.0  1.0  3.0  2.0    1.0   \n",
      "280  47.0  1.0    3.0  130.0  253.0    0.0  0.0  179.0  0.0  0.0  1.0    0.0   \n",
      "281  55.0  0.0    4.0  128.0  205.0    0.0  1.0  130.0  1.0  2.0  2.0    1.0   \n",
      "282  35.0  1.0    2.0  122.0  192.0    0.0  0.0  174.0  0.0  0.0  1.0    0.0   \n",
      "283  61.0  1.0    4.0  148.0  203.0    0.0  0.0  161.0  0.0  0.0  1.0    1.0   \n",
      "284  58.0  1.0    4.0  114.0  318.0    0.0  1.0  140.0  0.0  4.4  3.0    3.0   \n",
      "285  58.0  0.0    4.0  170.0  225.0    1.0  2.0  146.0  1.0  2.8  2.0    2.0   \n",
      "286  58.0  1.0    2.0  125.0  220.0    0.0  0.0  144.0  0.0  0.4  2.0    0.0   \n",
      "287  56.0  1.0    2.0  130.0  221.0    0.0  2.0  163.0  0.0  0.0  1.0    0.0   \n",
      "288  56.0  1.0    2.0  120.0  240.0    0.0  0.0  169.0  0.0  0.0  3.0    0.0   \n",
      "289  67.0  1.0    3.0  152.0  212.0    0.0  2.0  150.0  0.0  0.8  2.0    0.0   \n",
      "290  55.0  0.0    2.0  132.0  342.0    0.0  0.0  166.0  0.0  1.2  1.0    0.0   \n",
      "291  44.0  1.0    4.0  120.0  169.0    0.0  0.0  144.0  1.0  2.8  3.0    0.0   \n",
      "292  63.0  1.0    4.0  140.0  187.0    0.0  2.0  144.0  1.0  4.0  1.0    2.0   \n",
      "293  63.0  0.0    4.0  124.0  197.0    0.0  0.0  136.0  1.0  0.0  2.0    0.0   \n",
      "294  41.0  1.0    2.0  120.0  157.0    0.0  0.0  182.0  0.0  0.0  1.0    0.0   \n",
      "295  59.0  1.0    4.0  164.0  176.0    1.0  2.0   90.0  0.0  1.0  2.0    2.0   \n",
      "296  57.0  0.0    4.0  140.0  241.0    0.0  0.0  123.0  1.0  0.2  2.0    0.0   \n",
      "297  45.0  1.0    1.0  110.0  264.0    0.0  0.0  132.0  0.0  1.2  2.0    0.0   \n",
      "298  68.0  1.0    4.0  144.0  193.0    1.0  0.0  141.0  0.0  3.4  2.0    2.0   \n",
      "299  57.0  1.0    4.0  130.0  131.0    0.0  0.0  115.0  1.0  1.2  2.0    1.0   \n",
      "300  57.0  0.0    2.0  130.0  236.0    0.0  2.0  174.0  0.0  0.0  2.0    1.0   \n",
      "301  38.0  1.0    3.0  138.0  175.0    0.0  0.0  173.0  0.0  0.0  1.0    0.0   \n",
      "\n",
      "     6.0  \n",
      "271  7.0  \n",
      "272  3.0  \n",
      "273  3.0  \n",
      "274  7.0  \n",
      "275  3.0  \n",
      "276  3.0  \n",
      "277  3.0  \n",
      "278  3.0  \n",
      "279  7.0  \n",
      "280  3.0  \n",
      "281  7.0  \n",
      "282  3.0  \n",
      "283  7.0  \n",
      "284  6.0  \n",
      "285  6.0  \n",
      "286  7.0  \n",
      "287  7.0  \n",
      "288  3.0  \n",
      "289  7.0  \n",
      "290  3.0  \n",
      "291  6.0  \n",
      "292  7.0  \n",
      "293  3.0  \n",
      "294  3.0  \n",
      "295  6.0  \n",
      "296  7.0  \n",
      "297  7.0  \n",
      "298  7.0  \n",
      "299  7.0  \n",
      "300  3.0  \n",
      "301  3.0  \n",
      "\n",
      "y_train\n",
      "0      1\n",
      "1      1\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "266    1\n",
      "267    1\n",
      "268    0\n",
      "269    1\n",
      "270    0\n",
      "Name: 0, Length: 271, dtype: int64\n",
      "\n",
      "y_test\n",
      "271    1\n",
      "272    0\n",
      "273    1\n",
      "274    0\n",
      "275    0\n",
      "276    0\n",
      "277    1\n",
      "278    0\n",
      "279    1\n",
      "280    0\n",
      "281    1\n",
      "282    0\n",
      "283    1\n",
      "284    1\n",
      "285    1\n",
      "286    0\n",
      "287    0\n",
      "288    0\n",
      "289    1\n",
      "290    0\n",
      "291    1\n",
      "292    1\n",
      "293    1\n",
      "294    0\n",
      "295    1\n",
      "296    1\n",
      "297    1\n",
      "298    1\n",
      "299    1\n",
      "300    1\n",
      "301    0\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "split = int(np.floor(y.shape[0] * train_test_ratio))\n",
    "\n",
    "X_train = X.iloc[:split, :y_shape - 1]\n",
    "X_test = X.iloc[split:, :y_shape - 1]\n",
    "print(\"\\nX_train\")\n",
    "print(X_train)\n",
    "print(\"\\nX_test\")\n",
    "print(X_test)\n",
    "\n",
    "y_train = y.iloc[:split]\n",
    "y_test = y.iloc[split:]\n",
    "print(\"\\ny_train\")\n",
    "y_train = y_train.replace(to_replace=[2,3,4], value=[1,1,1])\n",
    "print(y_train)\n",
    "print(\"\\ny_test\")\n",
    "y_test = y_test.replace(to_replace=[2,3,4], value=[1,1,1])\n",
    "print(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pytorch Datasets\n",
    "Custom datasets for training and validation sets.\n",
    "The input parameters are given as Pandas dataframes representing given __X_train/y_train__ and __X_test/y_test sets__."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [],
   "source": [
    "class HeartTrainSet(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        X_train = X.to_numpy()\n",
    "        y_train = y.to_numpy()\n",
    "\n",
    "        self.X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "        self.y_train = torch.tensor(y_train)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_train[index], self.y_train[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "\n",
    "\n",
    "class HeartTestSet(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        X_test = X.to_numpy()\n",
    "        y_test = y.to_numpy()\n",
    "\n",
    "        self.X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "        self.y_test = torch.tensor(y_test)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_test[index], self.y_test[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression Model built using Pytorch built-in nn.Module"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "        torch.nn.init.xavier_normal(self.linear.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.linear(x)\n",
    "        return outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize Pytorch train and test datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [],
   "source": [
    "heart_train_set = HeartTrainSet(X_train, y_train)\n",
    "heart_test_set = HeartTestSet(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize Pytorch DataLoaders for iterating"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(heart_train_set, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(heart_test_set, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initalize model, loss function, and optimization algorithm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mithu\\AppData\\Local\\Temp/ipykernel_16752/1634558504.py:5: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  torch.nn.init.xavier_normal(self.linear.weight)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(13, 2)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Detect avalible devices for Pytorch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "#\"cuda\" if torch.cuda.is_available() else\n",
    "device = \"cpu\"\n",
    "\n",
    "print(\"Using {} device\".format(device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train and Test methods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, scheduler):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"Loss: {loss:>7f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\nAccuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train and Test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Loss: 7.273410\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.418936 \n",
      "\n",
      "Epoch 2:\n",
      "Loss: 3.502120\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.322720 \n",
      "\n",
      "Epoch 3:\n",
      "Loss: 3.263786\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.294054 \n",
      "\n",
      "Epoch 4:\n",
      "Loss: 3.217453\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.271757 \n",
      "\n",
      "Epoch 5:\n",
      "Loss: 3.189638\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.252384 \n",
      "\n",
      "Epoch 6:\n",
      "Loss: 3.167383\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.235251 \n",
      "\n",
      "Epoch 7:\n",
      "Loss: 3.148445\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.220037 \n",
      "\n",
      "Epoch 8:\n",
      "Loss: 3.132063\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.206480 \n",
      "\n",
      "Epoch 9:\n",
      "Loss: 3.117783\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.194387 \n",
      "\n",
      "Epoch 10:\n",
      "Loss: 3.105279\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.183587 \n",
      "\n",
      "Epoch 11:\n",
      "Loss: 3.094291\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.173931 \n",
      "\n",
      "Epoch 12:\n",
      "Loss: 3.084606\n",
      "Test Error: \n",
      "Accuracy: 61.3%, Avg loss: 3.165294 \n",
      "\n",
      "Epoch 13:\n",
      "Loss: 3.076045\n",
      "Test Error: \n",
      "Accuracy: 61.3%, Avg loss: 3.157562 \n",
      "\n",
      "Epoch 14:\n",
      "Loss: 3.068463\n",
      "Test Error: \n",
      "Accuracy: 61.3%, Avg loss: 3.150634 \n",
      "\n",
      "Epoch 15:\n",
      "Loss: 3.061738\n",
      "Test Error: \n",
      "Accuracy: 61.3%, Avg loss: 3.144425 \n",
      "\n",
      "Epoch 16:\n",
      "Loss: 3.055756\n",
      "Test Error: \n",
      "Accuracy: 61.3%, Avg loss: 3.138856 \n",
      "\n",
      "Epoch 17:\n",
      "Loss: 3.050436\n",
      "Test Error: \n",
      "Accuracy: 61.3%, Avg loss: 3.133860 \n",
      "\n",
      "Epoch 18:\n",
      "Loss: 3.045694\n",
      "Test Error: \n",
      "Accuracy: 61.3%, Avg loss: 3.129376 \n",
      "\n",
      "Epoch 19:\n",
      "Loss: 3.041463\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.125353 \n",
      "\n",
      "Epoch 20:\n",
      "Loss: 3.037685\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.121740 \n",
      "\n",
      "Epoch 21:\n",
      "Loss: 3.034309\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.118495 \n",
      "\n",
      "Epoch 22:\n",
      "Loss: 3.031286\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.115576 \n",
      "\n",
      "Epoch 23:\n",
      "Loss: 3.028584\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.112956 \n",
      "\n",
      "Epoch 24:\n",
      "Loss: 3.026161\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.110599 \n",
      "\n",
      "Epoch 25:\n",
      "Loss: 3.023991\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.108488 \n",
      "\n",
      "Epoch 26:\n",
      "Loss: 3.022050\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.106582 \n",
      "\n",
      "Epoch 27:\n",
      "Loss: 3.020300\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.104871 \n",
      "\n",
      "Epoch 28:\n",
      "Loss: 3.018736\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.103332 \n",
      "\n",
      "Epoch 29:\n",
      "Loss: 3.017332\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.101954 \n",
      "\n",
      "Epoch 30:\n",
      "Loss: 3.016070\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.100706 \n",
      "\n",
      "Epoch 31:\n",
      "Loss: 3.014938\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.099585 \n",
      "\n",
      "Epoch 32:\n",
      "Loss: 3.013920\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.098581 \n",
      "\n",
      "Epoch 33:\n",
      "Loss: 3.013006\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.097677 \n",
      "\n",
      "Epoch 34:\n",
      "Loss: 3.012184\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.096862 \n",
      "\n",
      "Epoch 35:\n",
      "Loss: 3.011446\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.096129 \n",
      "\n",
      "Epoch 36:\n",
      "Loss: 3.010782\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.095469 \n",
      "\n",
      "Epoch 37:\n",
      "Loss: 3.010188\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.094875 \n",
      "\n",
      "Epoch 38:\n",
      "Loss: 3.009650\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.094344 \n",
      "\n",
      "Epoch 39:\n",
      "Loss: 3.009169\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.093863 \n",
      "\n",
      "Epoch 40:\n",
      "Loss: 3.008737\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.093433 \n",
      "\n",
      "Epoch 41:\n",
      "Loss: 3.008348\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.093043 \n",
      "\n",
      "Epoch 42:\n",
      "Loss: 3.007996\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.092692 \n",
      "\n",
      "Epoch 43:\n",
      "Loss: 3.007679\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.092377 \n",
      "\n",
      "Epoch 44:\n",
      "Loss: 3.007397\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.092097 \n",
      "\n",
      "Epoch 45:\n",
      "Loss: 3.007142\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.091844 \n",
      "\n",
      "Epoch 46:\n",
      "Loss: 3.006914\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.091610 \n",
      "\n",
      "Epoch 47:\n",
      "Loss: 3.006706\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.091406 \n",
      "\n",
      "Epoch 48:\n",
      "Loss: 3.006521\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.091219 \n",
      "\n",
      "Epoch 49:\n",
      "Loss: 3.006355\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.091054 \n",
      "\n",
      "Epoch 50:\n",
      "Loss: 3.006205\n",
      "Test Error: \n",
      "Accuracy: 64.5%, Avg loss: 3.090902 \n",
      "\n",
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t + 1}:\")\n",
    "\n",
    "    train(train_dataloader, model, loss_fn, optimizer, scheduler)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "\n",
    "print(\"Training Complete\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [],
   "source": [
    "torch.save(model, \"models/logistic-regression\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "__Note:__ The average accuracy of the Logistic Regression model ranges from 40-50%. Due to the high irregularity of the small dataset and the nature of the data, low accuracy rates with logistic regression models are expected. However, further hyper-parameter tuning may improve performance.\n",
    "\n",
    "__Known Issues:__ Consistent oscillations in accuracy and testing error as well as fast but inconsistent convergence."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-6222d4bb",
   "language": "python",
   "display_name": "PyCharm (heart-nn)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}